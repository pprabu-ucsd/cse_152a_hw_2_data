{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e27ccce-385c-4363-9d4e-c9910ffc3918",
   "metadata": {},
   "source": [
    "# CSE 152A Winter 2023 â€“ Assignment 2\n",
    "\n",
    "\n",
    "- Assignment Published On: **Wednesday, January 31, 2024**\n",
    "\n",
    "- Due On: **Sunday, February 11 at 11:59 PM (Pacific Time)**\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Please answer the questions below using Python in the attached Jupyter notebook and follow the guidelines below:\n",
    " \n",
    "- This assignment must be completed **individually**. For more details, please follow the Academic Integrity Policy and Collaboration Policy posted on lecture slides.\n",
    "\n",
    "- All the solutions must be written in this Jupyter notebook.\n",
    "\n",
    "- After finishing the assignment in the notebook, please export the notebook as a PDF and submit both the notebook and the PDF (i.e. the `.ipynb` and the `.pdf` files) on Gradescope.\n",
    "\n",
    "- You may use basic algebra packages (e.g. `NumPy`, `SciPy`, etc) but you are not allowed to use open source codes that directly solve the problems. Feel free to ask the instructor and the teaching assistants if you are unsure about the packages to use.\n",
    "\n",
    "- It is highly recommended that you begin working on this assignment early.\n",
    "\n",
    "- Make sure that you read hints for questions (wherever given).\n",
    "\n",
    "**Late Policy:** Assignments submitted late will receive a 25% grade reduction for each 12 hours late (that is, 50% per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0388e-b949-405b-bf67-e03188e90825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "from skimage import io\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026882f-9b0f-4f28-8f92-ae423f74c4cc",
   "metadata": {},
   "source": [
    "## Problem 1: Edge & Corner Detection [23 pts]\n",
    "\n",
    "### Problem 1.1: Edge Detection [8 pts]\n",
    "\n",
    "In this problem, you will write a function to perform edge detection. The following steps need to be implemented.\n",
    "\n",
    "- **Smoothing [2 pt]:** First, we need to smooth the images to prevent noise from being considered edges. For this problem, use a 9x9 Gaussian kernel filter with $\\sigma = 1.2$ to smooth the images. Complete the `smooth` function.\n",
    "\n",
    "- **Gradient Computation [3+3 pts]:** After you have finished smoothing, find the image gradient in the horizontal and vertical directions. Compute the gradient magnitude image as $|G| = \\sqrt{G_x^2 + G_y^2}$  and gradient direction as $tan^{-1}(G_y/G_x)$.\n",
    "\n",
    "Compute the images after each step. Show each of the intermediate steps and label your images accordingly.\n",
    "\n",
    "In total, there should be four output images (original, smoothed, gradient magnitude, gradient direction).\n",
    "\n",
    "**For this question, use the image `geisel.jpeg`.**\n",
    "\n",
    "### **Hints**:\n",
    "- For calculating the gradient direction, consider using np.arctan2 to give a range [-180, 180] in degrees (https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html).\n",
    "\n",
    "- $G_x$ and $G_y$ are the image gradients along the x and y directions respectively. We can calculate these using convolution just like we did in HW1. You can use scipy's implementation of convolve through `convolve2d` which is imported for you. As mentioned in lecture slides, you can use these kernels for convolution:\n",
    "\n",
    "![Convolution Kernels for Image Gradients](./figs/convolution_hint.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf55e0-d4c8-405b-87cf-ed00d7331385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian2d(filter_size=1, sig=1.0):\n",
    "    \"\"\"\n",
    "    Creates 2D Gaussian kernel with side length `filter_size` and a sigma of `sig`.\n",
    "    Source: https://stackoverflow.com/a/43346070\n",
    "    \"\"\"\n",
    "    ax = np.arange(-filter_size // 2 + 1., filter_size // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sig))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def edge_detect(image):\n",
    "    \"\"\"\n",
    "    Perform edge detection on the image.\n",
    "    \"\"\"\n",
    "    smoothed = smooth(image)\n",
    "    g_mag, g_theta = gradient(smoothed)\n",
    "    return smoothed, g_mag, g_theta\n",
    "\n",
    "def smooth(image):\n",
    "    \"\"\"\n",
    "    Smoothes the image by using a 2D Gaussian kernel.\n",
    "    \n",
    "    Args:\n",
    "        image: input image (h,w)\n",
    "\n",
    "    Returns:\n",
    "        smooth_image: smoothed version of input image (h,w)\n",
    "    \"\"\"\n",
    "    smooth_image = np.zeros_like(image)\n",
    "    filter_size = 9 # Kernel size\n",
    "    sig = 1.2 # STD\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return smooth_image\n",
    "\n",
    "def gradient(image):\n",
    "    \"\"\"\n",
    "    Computes a gradient direction image and a gradient magnitude image.\n",
    "\n",
    "    Args:\n",
    "        image: input image (h,w)\n",
    "\n",
    "    Returns:\n",
    "        g_mag: gradient magnitude (h,w)\n",
    "        g_theta: gradient direction (h,w)\n",
    "    \"\"\"\n",
    "    g_mag = np.zeros_like(image)\n",
    "    g_theta = np.zeros_like(image)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return g_mag, g_theta\n",
    "\n",
    "# Plotting\n",
    "# Load image in grayscale\n",
    "image = io.imread(\"./imgs/geisel.jpeg\", as_gray=True)\n",
    "smoothed, g_mag, g_theta = edge_detect(image)\n",
    "print('Original:')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Smoothed:')\n",
    "plt.imshow(smoothed, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Gradient magnitude:')\n",
    "plt.imshow(g_mag, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Gradient direction:')\n",
    "plt.imshow(g_theta, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953058fd-0a10-456b-b8ef-ad33c4370732",
   "metadata": {},
   "source": [
    "### Problem 1.2: Corner Detection [15 pts]\n",
    "\n",
    "Next, you will implement a corner detector to detect corner-like features in the image.\n",
    "\n",
    "We can achieve this by looking at the minor eigenvalue of the second-moment matrix of local regions within the image. You need fill in the function `corner_detect` and call it with the correct arguments.\n",
    "\n",
    "**For each image, you should detect the 100 corners with the largest minor eigenvalue using a Gaussian standard deviation of 2.0 and a window size of 13.**\n",
    "\n",
    "Display the corners using the show_corners_result function and plot the minor eigenvalue images using the show_eigen_images function.\n",
    "\n",
    "**For this question, we will use images `im0.png` and `im1.png`**\n",
    "Data obtained from the Middlebury dataset (https://vision.middlebury.edu/stereo/data/)\n",
    "\n",
    "### **Hints**:\n",
    "\n",
    "- Again, you can use convolution to compute the image gradients.\n",
    "\n",
    "![Convolution Kernels for Image Gradients](./figs/convolution_hint.png)\n",
    "\n",
    "- The corners obtained in your result may not land exactly on top of the corner you see in the image. This is expected and is because with the material we've covered, we have only found the location of the region with the highest minor eigenvalue. We have not yet narrowed down the actual location within the window.\n",
    "\n",
    "- The approach discussed in lecture gives us \"corner-like\" features. This means that you should not expect that all corners would land on only corners that you might expect. Corners would appear in locations in the image as long as it fits the mathematical derivation we've discussed. It is normal for there to be some variance.\n",
    "  \n",
    "- For filtering/sliding windows, you may find it easy to think about the center pixel of odd length window sizes. You can use this to think out how to index through the image matrix.\n",
    "\n",
    "- You also may want to consider ignoring edge values when performing your filtering operations. The edge values can contain noisy estimates and produce unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36313f84-76bf-44a3-b14c-e77a26d1a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_detect(image, n_corners, smooth_std, window_size):\n",
    "    \"\"\"\n",
    "    Detect corners on a given image\n",
    "\n",
    "    Args:\n",
    "        image: 2D grayscale image on which to detect corners\n",
    "        n_corners: Total number of corners to be extracted\n",
    "        smooth_std: Standard deviation of the Gaussian smoothing kernel\n",
    "        window_size: Window size for Gaussian smoothing kernel,\n",
    "                     corner detection, and nonmaximum suppresion\n",
    "\n",
    "    Returns:\n",
    "        minor_eig_image: The minor eigenvalue image (same shape as image)\n",
    "        corners: Detected corners (in x-y coordinates) in a numpy array of shape (n_corners, 2)\n",
    "    \"\"\"\n",
    "    minor_eig_image = np.zeros_like(image)\n",
    "    corners = np.zeros((n_corners, 2))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return minor_eig_image, corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22a7e0-9816-4b14-82e0-f94f7d10d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eigen_images(imgs):\n",
    "    print(\"Minor Eigen value images\")\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    # Plot image 1\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(imgs[0], cmap='gray')\n",
    "    plt.title('Image 0')\n",
    "\n",
    "    # Plot image 2\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(imgs[1], cmap='gray')\n",
    "    plt.title('Image 1')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def show_corners_result(imgs, corners, window_size):\n",
    "    print(\"Detected Corners\")\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.imshow(imgs[0], cmap='gray')\n",
    "    ax1.scatter(corners[0][:, 0], corners[0][:, 1], s=25, edgecolors='r', facecolors='none')\n",
    "    ax1.title.set_text(\"Image 0\")\n",
    "\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.imshow(imgs[1], cmap='gray')\n",
    "    ax2.scatter(corners[1][:, 0], corners[1][:, 1], s=25, edgecolors='r', facecolors='none')\n",
    "    ax2.title.set_text(\"Image 1\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a52e77-1cfc-43ea-94e0-7a0626067949",
   "metadata": {},
   "source": [
    "### You may want to modify these parameters here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1f784-cdc1-4c44-825b-75ab89615f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect corners on the two provided images\n",
    "\n",
    "# You may want to change these parameters accordingly\n",
    "n_corners = 1\n",
    "smooth_std = 1\n",
    "window_size = 1\n",
    "\n",
    "# Read images and detect corners on images\n",
    "imgs = []\n",
    "eig_imgs = []\n",
    "corners = []\n",
    "for i in range(2):\n",
    "    img = io.imread(f\"./imgs/im{i}.png\", as_gray=True)\n",
    "    imgs.append(img)\n",
    "    #img = io.imread('im' + str(i) + '.png')\n",
    "    minor_eig_image, corners_vals = corner_detect(imgs[-1], n_corners, smooth_std, window_size)\n",
    "    eig_imgs.append(minor_eig_image)\n",
    "    corners.append(corners_vals)\n",
    "\n",
    "# Show the results\n",
    "# This may take a few seconds to run\n",
    "show_eigen_images(eig_imgs)\n",
    "show_corners_result(imgs, corners, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd686f3e-a1eb-49d1-a004-fa8d0ced859d",
   "metadata": {},
   "source": [
    "## Problem 2: Theory [20 points]\n",
    "### Problem 2.1: Epipolar Geometry [10 points]\n",
    "\n",
    "Consider two cameras whose image planes are the z=2 plane, and whose focal points are at (-2, 0, 0) and (8, 0, 0). See Fig 1.1 below. We'll call a point in the first camera (x, y), and a point in the second camera (u, v). Points in each camera are relative to the camera center. So, for example if (x, y) = (0, 0), this is really the point (-2, 0, 2) in world coordinates, while if (u, v) = (0, 0) this is the point (8, 0, 2).\n",
    "\n",
    "Suppose the point $(x,y)=(3,3)$ is matched to the point $(u,v)=(1,3)$. What is the 3D location of this point?\n",
    "\n",
    "### **Hint**:\n",
    "One way of solving this is to think about the intersection of the rays.\n",
    "![fig 2.1](./figs/p2_1_figure.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccfdaf4-571d-4105-9575-0e8d459713ff",
   "metadata": {},
   "source": [
    "### Problem 2.2: The Epipolar Constraint [5 points]\n",
    "\n",
    "Suppose two cameras fixate on a point $P$ in space such that their principal axes intersect at that point. (See the fig. 1.2 below.) Show that if the image coordinates are normalized so that the coordinate origin (0, 0) coincides with the principal point, then the $F_{33}$ element of the fundamental matrix is zero.\n",
    "\n",
    "![fig 2.2](./figs/ec_diagram.png)\n",
    "\n",
    "In the figure, $C1$ and $C2$ are the optical centers. The principal axes intersect at point $P$.\n",
    "\n",
    "### **Hint**:\n",
    " \n",
    "You will be required to convert the points into homogeneous coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b8fc3-9959-4c5b-9e59-fea91cf8580b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Problem 2.3: Essential Matrix [5 points]\n",
    "\n",
    "Suppose a stereo rig is formed of two cameras: the rotation matrix and translation vector are given to you. Please write down the essential matrix. Also, compute the rank of the essential matrix using SVD, i.e., the number of nonzero singular values. (Note that if you get a singular value $s$ of a very small number in your calculation, e.g., $s<=1e-15$, you can treat it as zero singular value). \n",
    "\n",
    "\n",
    "$$ R=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\sqrt{3}}{2} & \\frac{1}{2} & 0 \\\\\n",
    "-\\frac{1}{2} & \\frac{\\sqrt{3}}{2} & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ t=\n",
    "\\begin{bmatrix}\n",
    "4 \\\\ 2 \\\\3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **Hint**:\n",
    " \n",
    "You may find the following implementation of SVD useful: https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cac8f4-a275-49e3-baac-9c6960eaa360",
   "metadata": {},
   "source": [
    "## Problem 3: SSD (Sum Squared Distance) and NCC (Normalized Cross-Correlation) Matching [21 points]\n",
    "In this part, you have to write two functions <code>ssd_match</code> and <code>ncc_match</code> that implement the computation of the matching score for two given windows with SSD and NCC metrics respectively.\n",
    "\n",
    "### Problem 3.1: SSD (Sum Squared Distance) Matching [5 points]\n",
    "Complete the function <code>ssd_match</code>:  \n",
    "SSD = $\\sum_{x,y}|W_1(x,y)-W_2(x,y)|^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6e9f1-5b91-46b8-9237-cae1044b063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_match(img1, img2, c1, c2, R):\n",
    "    \"\"\"\n",
    "    Compute SSD of two windows.\n",
    "    \n",
    "    Args:\n",
    "        img1: Image 1.\n",
    "        img2: Image 2.\n",
    "        c1: Center (in x-y coordinates) of the window in image 1.\n",
    "        c2: Center (in x-y coordinates) of the window in image 2.\n",
    "        R: R is the radius of the patch, 2 * R + 1 is the window size\n",
    "\n",
    "    Returns:\n",
    "        SSD matching score for two input windows (a scalar value).\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return matching_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89affaa-2a2a-4983-b936-fc70c0a6ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for you to test your implementation\n",
    "img1 = np.array([[1, 2, 3, 4], [4, 5, 6, 8], [7, 8, 9, 4]])\n",
    "img2 = np.array([[1, 2, 1, 3], [6, 5, 4, 4], [9, 8, 7, 3]])\n",
    "\n",
    "result1 = ssd_match(img1, img2, np.array([1, 1]), np.array([1, 1]), 1)\n",
    "# should print 20\n",
    "assert(result1 == 20)\n",
    "print(f\"Result 1: {result1}\")\n",
    "\n",
    "result2 = ssd_match(img1, img2, np.array([2, 1]), np.array([2, 1]), 1)\n",
    "# should print 30\n",
    "assert(result2 == 30)\n",
    "print(f\"Result 2: {result2}\")\n",
    "\n",
    "result3 = ssd_match(img1, img2, np.array([1, 1]), np.array([2, 1]), 1)\n",
    "# should print 46\n",
    "assert(result3 == 46)\n",
    "print(f\"Result 3: {result3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772dd86-eab8-4cba-9d7c-fefc61255174",
   "metadata": {},
   "source": [
    "### Problem 3.2: NCC (Normalized Cross-Correlation) Matching [8 points]\n",
    "Complete the function <code>ncc_match</code>:\n",
    "\n",
    "NCC = $\\sum_{x,y}\\tilde{W_1} (x,y)\\cdot \\tilde{W_2} (x,y)$ \n",
    "\n",
    "where $\\tilde{W} = \\frac{W - \\overline{W}}{\\sqrt{\\sum_{x,y}(W(x,y) - \\overline{W})^2}}$ is a mean-shifted and normalized version of the window and $\\overline{W}$ is the mean pixel value in the window W.\n",
    "\n",
    "There may be other slightly different formulations of NCC, however you should utilize this one for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a246fb-a9fc-4ec4-87f4-af3971532f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_match(img1, img2, c1, c2, R):\n",
    "    \"\"\"\n",
    "    Compute NCC given two windows.\n",
    "\n",
    "    Args:\n",
    "        img1: Image 1.\n",
    "        img2: Image 2.\n",
    "        c1: Center (in image coordinate) of the window in image 1.\n",
    "        c2: Center (in image coordinate) of the window in image 2.\n",
    "        R: R is the radius of the patch, 2 * R + 1 is the window size\n",
    "\n",
    "    Returns:\n",
    "        NCC matching score for two input windows.\n",
    "\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return matching_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d67407-65a6-4361-ae0b-af9fb8c001d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for you to test your implementation\n",
    "img1 = np.array([[1, 2, 3, 4], [4, 5, 6, 8], [7, 8, 9, 4]])\n",
    "img2 = np.array([[1, 2, 1, 3], [6, 5, 4, 4], [9, 8, 7, 3]])\n",
    "\n",
    "result4 = ncc_match(img1, img2, np.array([1, 1]), np.array([1, 1]), 1)\n",
    "# should print 0.8546\n",
    "print(f\"Result 4: {result4}\")\n",
    "\n",
    "result5 = ncc_match(img1, img2, np.array([2, 1]), np.array([2, 1]), 1)\n",
    "# should print 0.8457\n",
    "print(f\"Result 5: {result5}\")\n",
    "\n",
    "result6 = ncc_match(img1, img2, np.array([1, 1]), np.array([2, 1]), 1)\n",
    "# should print 0.6258\n",
    "print(f\"Result 6: {result6}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59debf18-a2c2-44e3-ba11-dcbb51245dfc",
   "metadata": {},
   "source": [
    "### Problem 3.3: Naive Matching [8 points]\n",
    "\n",
    "Given the corner points detected and the NCC matching function, we are ready to start finding correspondences. One naive strategy is to try and find the best match between the two sets of corner points. Write a function that does this, namely, for each corner in image1, find the best match from the detected corners in image2 (or, if the NCC match score is too low, then return no match for that point). \n",
    "\n",
    "Write a function <code>naive_matching</code> and call it as below. Examine your results for 20 detected corners in each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822894b-4d20-4cfb-925a-b9c4738e0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matching(img1, img2, corners1, corners2, R, NCCth):\n",
    "    \"\"\"\n",
    "    Compute NCC given two windows.\n",
    "\n",
    "    Args:\n",
    "        img1: Image 1.\n",
    "        img2: Image 2.\n",
    "        corners1: Corners in image 1 (nx2)\n",
    "        corners2: Corners in image 2 (nx2)\n",
    "        R: NCC matching radius\n",
    "        NCCth: NCC matching score threshold\n",
    "\n",
    "    Returns:\n",
    "        matching: NCC matching returns a list of tuple (c1, c2), \n",
    "                  c1 is the 1x2 corner location in image 1, \n",
    "                  c2 is the 1x2 corner location in image 2. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2b2fa-4e3d-43c9-b0b6-27bb8ca66a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    \"\"\" \n",
    "    Convert rgb image to grayscale.\n",
    "    \"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# Detect corners on warrior and matrix sets\n",
    "# You are free to modify the parameters if you wish\n",
    "n_corners = 20\n",
    "smooth_std = 1\n",
    "window_size = 17\n",
    "\n",
    "# Read images and detect corners on the images\n",
    "imgs_mat = []\n",
    "crns_mat = []\n",
    "imgs_war = []\n",
    "crns_war = []\n",
    "\n",
    "for i in range(2):\n",
    "    img_mat = io.imread('./imgs/p4/matrix/matrix' + str(i) + '.png')\n",
    "    imgs_mat.append(rgb2gray(img_mat))\n",
    "    img_war = io.imread('./imgs/p4/warrior/warrior' + str(i) + '.png')\n",
    "    imgs_war.append(rgb2gray(img_war))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c319ab0-133c-4a3e-addc-46be19df4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match corners (May need to modify the threshold below)\n",
    "crnsmatf=open('./imgs/p3/crns_mat.pkl','rb')\n",
    "crns_mat=pickle.load(crnsmatf)\n",
    "crnswarf=open('./imgs/p3/crns_war.pkl','rb')\n",
    "crns_war=pickle.load(crnswarf)\n",
    "R = 120\n",
    "NCCth = 0.6  # MAY NEED TO MODIFY YOUR THRESHOLD HERE\n",
    "matching_mat = naive_matching(imgs_mat[0]/255, imgs_mat[1]/255, crns_mat[0], crns_mat[1], R, NCCth)\n",
    "matching_war = naive_matching(imgs_war[0]/255, imgs_war[1]/255, crns_war[0], crns_war[1], R, NCCth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad672fe4-28a7-4611-8374-76395ee267aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matching result\n",
    "def show_matching_result(img1, img2, matching):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.hstack((img1, img2)), cmap='gray') # two dino images are of different sizes, resize one before use\n",
    "    for p1, p2 in matching:\n",
    "        plt.scatter(p1[0], p1[1], s=35, edgecolors='r', facecolors='none')\n",
    "        plt.scatter(p2[0] + img1.shape[1], p2[1], s=35, edgecolors='r', facecolors='none')\n",
    "        plt.plot([p1[0], p2[0] + img1.shape[1]], [p1[1], p2[1]])\n",
    "    #plt.savefig('matching.png')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Number of Corners:\", n_corners)\n",
    "show_matching_result(imgs_mat[0], imgs_mat[1], matching_mat)\n",
    "show_matching_result(imgs_war[0], imgs_war[1], matching_war)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ba961-ce8f-42b1-b1ee-ee3f07f0ccf3",
   "metadata": {},
   "source": [
    "## Problem 4: Epipolar Geometry [13 points]\n",
    "\n",
    "As shown in Problem 2, the naive mathing algorithm is simple. The weakness of this method comes from the high matching complexity. In this problem, we will explore how to visualize epipolar geometry constraint in the form of epipolar lines. This constraint we could to rectify the images and build a better matching algorithm (outside of the scope of this assignment).\n",
    "\n",
    "### Problem 4.1: Fundamental matrix [10 points]\n",
    "Complete the <code>compute_fundamental</code> function below using the 8-point algorithm described in lecture. Note that the normalization of the corner points is handled in the <code>fundamental_matrix</code> function. We have handled constraining $F$ to be of rank 2 for you.\n",
    "\n",
    "### **Hint**:\n",
    "This portion requires you to build the constraint matrix $A$ for the 8-point algorithm. We can solve for the fundamental matrix by applying SVD to this matrix. Your task will be to construct the equation given below in code and compute the linear least square solution through SVD.\n",
    "\n",
    "When you try to find the non-trivial solution to a linear system of equations $Af=0$, you can use singular value decomposition where f will be given by the singular vector corresponding to the smallest singular value. It would be stored in the last column of $V$. You may use Numpy's SVD implementation, but be aware that it returns $V^T$, and not $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243df35-9dbb-4e10-aa06-77c80049ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1, x2):\n",
    "    \"\"\"\n",
    "    Computes the fundamental matrix from corresponding points \n",
    "    (x1,x2 3xn arrays) using the 8 point algorithm.\n",
    "        \n",
    "    Construct the A matrix according to lecture\n",
    "    and solve the system of equations for the entries of the fundamental matrix.\n",
    "\n",
    "    Args:\n",
    "        x1: Point correspondences from img1 (3xn)\n",
    "        x2: Point correspondences from img2 (3xn)\n",
    "    \n",
    "    Returns:\n",
    "        Fundamental Matrix (3x3)\n",
    "    \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don't match.\")\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    \n",
    "    return F/F[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6ac6c-b0b4-467b-b3a1-e453e8bda89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fundamental_matrix(x1,x2):\n",
    "    # Normalization of the corner points is handled here\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don't match.\")\n",
    "\n",
    "    # normalize image coordinates\n",
    "    x1 = x1 / x1[2]\n",
    "    mean_1 = np.mean(x1[:2],axis=1)\n",
    "    S1 = np.sqrt(2) / np.std(x1[:2])\n",
    "    T1 = np.array([[S1,0,-S1*mean_1[0]],[0,S1,-S1*mean_1[1]],[0,0,1]])\n",
    "    x1 = np.dot(T1,x1)\n",
    "    \n",
    "    x2 = x2 / x2[2]\n",
    "    mean_2 = np.mean(x2[:2],axis=1)\n",
    "    S2 = np.sqrt(2) / np.std(x2[:2])\n",
    "    T2 = np.array([[S2,0,-S2*mean_2[0]],[0,S2,-S2*mean_2[1]],[0,0,1]])\n",
    "    x2 = np.dot(T2,x2)\n",
    "\n",
    "    # compute F with the normalized coordinates\n",
    "    F = compute_fundamental(x1,x2)\n",
    "\n",
    "    # reverse normalization\n",
    "    F = np.dot(T2.T,np.dot(F,T1))\n",
    "\n",
    "    return F/F[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6917bf-af23-4414-8aa6-77c887dcf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for you to test your implementation\n",
    "cor1 = np.load(\"./imgs/p4/\"+'dino'+\"/cor1.npy\")\n",
    "cor2 = np.load(\"./imgs/p4/\"+'dino'+\"/cor2.npy\")\n",
    "print(fundamental_matrix(cor1,cor2))\n",
    "# Should print \n",
    "#[[ 4.00502510e-07 -2.69900666e-06  1.37819769e-03]\n",
    "# [ 3.09619039e-06 -1.00972419e-08 -7.29675791e-03]\n",
    "# [-2.86966053e-03  6.70452915e-03  1.00000000e+00]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64ed2c-52df-4cf1-b885-0f5b251df67d",
   "metadata": {},
   "source": [
    "### Problem 4.2: Plot Epipolar Lines [3 points]\n",
    "\n",
    "**You do not need to code anything here. Run the cells below and look at your results**\n",
    "\n",
    "Using this fundamental matrix, we can plot the epipolar lines in both images for each image pair. For this part, you just have to use the function <code>plot_epipolar_lines</code> and check for the correctness of <code>compute_fundamental</code> that you have already written in Q4.1). Show your result for matrix and warrior as exemplified by the figure below. \n",
    "\n",
    "![Dino Epipolar 1](./figs/dinoEpi1.png)\n",
    "![Dino Epipolar 2](./figs/dinoEpi2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bb4c8-df3c-4c72-b1e5-392431b642dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epipolar_lines(img1, img2, cor1, cor2):\n",
    "    \"\"\"\n",
    "    Plot epipolar lines on image given image, corners\n",
    "\n",
    "    Args:\n",
    "        img1: Image 1.\n",
    "        img2: Image 2.\n",
    "        cor1: Corners in homogeneous image coordinate in image 1 (3xn)\n",
    "        cor2: Corners in homogeneous image coordinate in image 2 (3xn)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cor1.shape[0] == 3\n",
    "    assert cor2.shape[0] == 3\n",
    "    assert cor1.shape == cor2.shape\n",
    "    \n",
    "    F = fundamental_matrix(cor1, cor2)\n",
    "        \n",
    "    # epipole in image 1 is the solution to Fe = 0\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e1 = V[-1]\n",
    "    e1 /= e1[-1]\n",
    "    \n",
    "    # epipole in image 2 is the solution to F.Te = 0\n",
    "    U,S,V = np.linalg.svd(F.T)\n",
    "    e2 = V[-1]\n",
    "    e2 /= e2[-1]\n",
    "\n",
    "    plot_epipoles = False\n",
    "    \n",
    "    # Plot epipolar lines in the first image\n",
    "    # There is an epipolar line for each corner\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    h, w = img1.shape[:2]\n",
    "    for c2 in cor2.T:\n",
    "        # epipolar line is (F.T * c2) dot (x, y, 1) = 0\n",
    "        epi_line = np.dot(F.T, c2)\n",
    "        a, b, c = epi_line # ax + by + c = 0, y = -a/b * x - c/b\n",
    "        x = np.arange(w)\n",
    "        y = (-a / b) * x - (c / b)\n",
    "        x = np.array([x[i] for i in range(x.size) if y[i] >=0 and y[i] < h - 1])\n",
    "        y = np.array([y[i] for i in range(y.size) if y[i] >=0 and y[i] < h - 1])\n",
    "        plt.plot(x, y, 'b', zorder=1)\n",
    "        \n",
    "    plt.scatter(cor1[0], cor1[1], s=50, edgecolors='b', facecolors='r', zorder=2)\n",
    "    \n",
    "    if plot_epipoles:\n",
    "        plt.scatter([e1[0]], [e1[1]], s=75, edgecolors='g', facecolors='y', zorder=3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot epipolar lines in the second image\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    h, w = img2.shape[:2]\n",
    "    \n",
    "    for c1 in cor1.T:\n",
    "        # epipolar line is (F * c1) dot (x, y, 1) = 0\n",
    "        epi_line = np.dot(F, c1)\n",
    "        a, b, c = epi_line\n",
    "        x = np.arange(w)\n",
    "        y = (-a / b) * x - (c / b)\n",
    "        x = np.array([x[i] for i in range(x.size) if y[i] >=0 and y[i] < h - 1])\n",
    "        y = np.array([y[i] for i in range(y.size) if y[i] >=0 and y[i] < h - 1])\n",
    "        plt.plot(x, y, 'b', zorder=1)\n",
    "    \n",
    "    plt.scatter(cor2[0], cor2[1], s=50, edgecolors='b', facecolors='r', zorder=2)\n",
    "    \n",
    "    if plot_epipoles:\n",
    "        plt.scatter([e2[0]], [e2[1]], s=75, edgecolors='g', facecolors='y', zorder=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b818dd2-e461-43ff-959b-258f5ac40b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace images and corners with those of matrix and warrior\n",
    "imgids = [\"dino\", \"matrix\", \"warrior\"]\n",
    "for imgid in imgids:\n",
    "    I1 = io.imread(\"./imgs/p4/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I2 = io.imread(\"./imgs/p4/\"+imgid+\"/\"+imgid+\"1.png\")\n",
    "    cor1 = np.load(\"./imgs/p4/\"+imgid+\"/cor1.npy\")\n",
    "    cor2 = np.load(\"./imgs/p4/\"+imgid+\"/cor2.npy\")\n",
    "    plot_epipolar_lines(I1,I2,cor1,cor2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542e521-1816-4ebd-bb49-b3256654aee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
